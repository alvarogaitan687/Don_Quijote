2023-05-17 19:20:17,099 INFO util.ShutdownHookManager: Shutdown hook called
2023-05-17 19:20:17,099 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-7f4a6e4e-657f-470a-965e-5e4af13827f8
2023-05-17 19:20:17,102 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-7f4a6e4e-657f-470a-965e-5e4af13827f8/pyspark-2c9c5e5b-43ba-4190-8be7-bf5e472c8d56
2023-05-17 19:20:17,103 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-01cb8ae3-ef31-4f90-9355-0b308f5b454e
python3 words_count.py quijote.txt 
2023-05-17 19:20:27,637 INFO spark.SparkContext: Running Spark version 3.3.1
2023-05-17 19:20:27,703 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-05-17 19:20:27,794 INFO resource.ResourceUtils: ==============================================================
2023-05-17 19:20:27,794 INFO resource.ResourceUtils: No custom resources configured for spark.driver.
2023-05-17 19:20:27,795 INFO resource.ResourceUtils: ==============================================================
2023-05-17 19:20:27,795 INFO spark.SparkContext: Submitted application: pyspark-shell
2023-05-17 19:20:27,815 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2023-05-17 19:20:27,825 INFO resource.ResourceProfile: Limiting resource is cpu
2023-05-17 19:20:27,826 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0
2023-05-17 19:20:27,872 INFO spark.SecurityManager: Changing view acls to: alvagait
2023-05-17 19:20:27,872 INFO spark.SecurityManager: Changing modify acls to: alvagait
2023-05-17 19:20:27,873 INFO spark.SecurityManager: Changing view acls groups to: 
2023-05-17 19:20:27,873 INFO spark.SecurityManager: Changing modify acls groups to: 
2023-05-17 19:20:27,874 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(alvagait); groups with view permissions: Set(); users  with modify permissions: Set(alvagait); groups with modify permissions: Set()
2023-05-17 19:20:28,098 INFO util.Utils: Successfully started service 'sparkDriver' on port 39397.
2023-05-17 19:20:28,120 INFO spark.SparkEnv: Registering MapOutputTracker
2023-05-17 19:20:28,148 INFO spark.SparkEnv: Registering BlockManagerMaster
2023-05-17 19:20:28,161 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-05-17 19:20:28,162 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2023-05-17 19:20:28,164 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat
2023-05-17 19:20:28,180 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-bcb088ef-5251-4a1e-ab6a-559ebea03a6e
2023-05-17 19:20:28,192 INFO memory.MemoryStore: MemoryStore started with capacity 434.4 MiB
2023-05-17 19:20:28,203 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2023-05-17 19:20:28,239 INFO util.log: Logging initialized @1813ms to org.sparkproject.jetty.util.log.Slf4jLog
2023-05-17 19:20:28,321 INFO server.Server: jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.18+10-post-Debian-1deb11u1
2023-05-17 19:20:28,336 INFO server.Server: Started @1911ms
2023-05-17 19:20:28,361 INFO server.AbstractConnector: Started ServerConnector@4af8a4da{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2023-05-17 19:20:28,361 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2023-05-17 19:20:28,385 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@456cce45{/,null,AVAILABLE,@Spark}
2023-05-17 19:20:28,548 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://192.168.135.1:7077...
2023-05-17 19:20:28,602 INFO client.TransportClientFactory: Successfully created connection to /192.168.135.1:7077 after 27 ms (0 ms spent in bootstraps)
2023-05-17 19:20:28,667 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20230517192028-0424
2023-05-17 19:20:28,669 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20230517192028-0424/0 on worker-20230413105822-147.96.20.35-34415 (147.96.20.35:34415) with 8 core(s)
2023-05-17 19:20:28,671 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20230517192028-0424/0 on hostPort 147.96.20.35:34415 with 8 core(s), 1024.0 MiB RAM
2023-05-17 19:20:28,672 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20230517192028-0424/1 on worker-20230413113150-192.168.135.23-42655 (192.168.135.23:42655) with 4 core(s)
2023-05-17 19:20:28,672 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20230517192028-0424/1 on hostPort 192.168.135.23:42655 with 4 core(s), 1024.0 MiB RAM
2023-05-17 19:20:28,672 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20230517192028-0424/2 on worker-20230413113149-192.168.135.21-34617 (192.168.135.21:34617) with 4 core(s)
2023-05-17 19:20:28,673 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41791.
2023-05-17 19:20:28,673 INFO netty.NettyBlockTransferService: Server created on wild.mat.ucm.es:41791
2023-05-17 19:20:28,673 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20230517192028-0424/2 on hostPort 192.168.135.21:34617 with 4 core(s), 1024.0 MiB RAM
2023-05-17 19:20:28,673 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20230517192028-0424/3 on worker-20230413113149-192.168.135.14-36307 (192.168.135.14:36307) with 4 core(s)
2023-05-17 19:20:28,673 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20230517192028-0424/3 on hostPort 192.168.135.14:36307 with 4 core(s), 1024.0 MiB RAM
2023-05-17 19:20:28,673 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20230517192028-0424/4 on worker-20230413113149-192.168.135.11-39281 (192.168.135.11:39281) with 4 core(s)
2023-05-17 19:20:28,674 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20230517192028-0424/4 on hostPort 192.168.135.11:39281 with 4 core(s), 1024.0 MiB RAM
2023-05-17 19:20:28,674 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20230517192028-0424/5 on worker-20230413113149-192.168.135.15-41663 (192.168.135.15:41663) with 4 core(s)
2023-05-17 19:20:28,674 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20230517192028-0424/5 on hostPort 192.168.135.15:41663 with 4 core(s), 1024.0 MiB RAM
2023-05-17 19:20:28,674 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-05-17 19:20:28,679 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, wild.mat.ucm.es, 41791, None)
2023-05-17 19:20:28,682 INFO storage.BlockManagerMasterEndpoint: Registering block manager wild.mat.ucm.es:41791 with 434.4 MiB RAM, BlockManagerId(driver, wild.mat.ucm.es, 41791, None)
2023-05-17 19:20:28,685 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, wild.mat.ucm.es, 41791, None)
2023-05-17 19:20:28,686 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, wild.mat.ucm.es, 41791, None)
2023-05-17 19:20:28,688 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20230517192028-0424/0 is now RUNNING
2023-05-17 19:20:28,873 INFO history.SingleEventLogFileWriter: Logging events to file:/opt/spark/current/events/app-20230517192028-0424.inprogress
2023-05-17 19:20:28,930 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20230517192028-0424/4 is now RUNNING
2023-05-17 19:20:28,960 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20230517192028-0424/1 is now RUNNING
2023-05-17 19:20:28,987 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20230517192028-0424/3 is now RUNNING
2023-05-17 19:20:28,988 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20230517192028-0424/2 is now RUNNING
2023-05-17 19:20:29,003 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20230517192028-0424/5 is now RUNNING
2023-05-17 19:20:29,075 INFO handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@456cce45{/,null,STOPPED,@Spark}
2023-05-17 19:20:29,077 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b5a4441{/jobs,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,077 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@792a1d53{/jobs/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,078 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@49ca98ae{/jobs/job,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,079 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79817932{/jobs/job/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,080 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ac58873{/stages,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,080 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@585296e0{/stages/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,081 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@479b0030{/stages/stage,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,082 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40972fb8{/stages/stage/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,083 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@19754900{/stages/pool,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,083 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47ba59a4{/stages/pool/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,084 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@705bf52d{/storage,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,085 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@113deebd{/storage/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,086 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51927804{/storage/rdd,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,087 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5487c918{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,088 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@109dbf98{/environment,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,089 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c38e196{/environment/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,090 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1eea9e1a{/executors,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,091 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a8d76f1{/executors/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,093 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4718beca{/executors/threadDump,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,094 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@273801e9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,104 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f0f4ae2{/static,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,105 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a1361c1{/,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,106 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50029dde{/api,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,107 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4a2aa767{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,108 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@74cc1541{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,112 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1831ccb1{/metrics/json,null,AVAILABLE,@Spark}
2023-05-17 19:20:29,114 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2023-05-17 19:20:29,659 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 307.6 KiB, free 434.1 MiB)
2023-05-17 19:20:29,734 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 51.9 KiB, free 434.0 MiB)
2023-05-17 19:20:29,736 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on wild.mat.ucm.es:41791 (size: 51.9 KiB, free: 434.3 MiB)
2023-05-17 19:20:29,740 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
RESULTS------------------
2023-05-17 19:20:30,612 INFO mapred.FileInputFormat: Total input files to process : 1
2023-05-17 19:20:30,708 INFO spark.SparkContext: Starting job: sum at /home/alvagait/words_count.py:19
2023-05-17 19:20:30,726 INFO scheduler.DAGScheduler: Got job 0 (sum at /home/alvagait/words_count.py:19) with 2 output partitions
2023-05-17 19:20:30,726 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (sum at /home/alvagait/words_count.py:19)
2023-05-17 19:20:30,727 INFO scheduler.DAGScheduler: Parents of final stage: List()
2023-05-17 19:20:30,728 INFO scheduler.DAGScheduler: Missing parents: List()
2023-05-17 19:20:30,749 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at sum at /home/alvagait/words_count.py:19), which has no missing parents
2023-05-17 19:20:30,793 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.1 KiB, free 434.0 MiB)
2023-05-17 19:20:30,801 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.0 MiB)
2023-05-17 19:20:30,802 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on wild.mat.ucm.es:41791 (size: 5.5 KiB, free: 434.3 MiB)
2023-05-17 19:20:30,803 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
2023-05-17 19:20:30,820 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at sum at /home/alvagait/words_count.py:19) (first 15 tasks are for partitions Vector(0, 1))
2023-05-17 19:20:30,821 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
2023-05-17 19:20:31,137 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (147.96.20.35:50428) with ID 0,  ResourceProfileId 0
2023-05-17 19:20:31,264 INFO storage.BlockManagerMasterEndpoint: Registering block manager 147.96.20.35:44509 with 434.4 MiB RAM, BlockManagerId(0, 147.96.20.35, 44509, None)
2023-05-17 19:20:31,325 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (147.96.20.35, executor 0, partition 0, ANY, 4517 bytes) taskResourceAssignments Map()
2023-05-17 19:20:31,330 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (147.96.20.35, executor 0, partition 1, ANY, 4517 bytes) taskResourceAssignments Map()
2023-05-17 19:20:31,562 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 147.96.20.35:44509 (size: 5.5 KiB, free: 434.4 MiB)
2023-05-17 19:20:31,770 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 147.96.20.35:44509 (size: 51.9 KiB, free: 434.3 MiB)
2023-05-17 19:20:33,250 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1942 ms on 147.96.20.35 (executor 0) (1/2)
2023-05-17 19:20:33,255 INFO python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 41869
2023-05-17 19:20:33,278 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1949 ms on 147.96.20.35 (executor 0) (2/2)
2023-05-17 19:20:33,279 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2023-05-17 19:20:33,281 INFO scheduler.DAGScheduler: ResultStage 0 (sum at /home/alvagait/words_count.py:19) finished in 2,502 s
2023-05-17 19:20:33,285 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2023-05-17 19:20:33,285 INFO scheduler.TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2023-05-17 19:20:33,287 INFO scheduler.DAGScheduler: Job 0 finished: sum at /home/alvagait/words_count.py:19, took 2,578695 s
words_count 381225                                                              
2023-05-17 19:20:33,305 INFO server.AbstractConnector: Stopped Spark@4af8a4da{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2023-05-17 19:20:33,306 INFO ui.SparkUI: Stopped Spark web UI at http://wild.mat.ucm.es:4040
2023-05-17 19:20:33,308 INFO cluster.StandaloneSchedulerBackend: Shutting down all executors
2023-05-17 19:20:33,309 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
2023-05-17 19:20:33,325 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2023-05-17 19:20:33,351 INFO memory.MemoryStore: MemoryStore cleared
2023-05-17 19:20:33,352 INFO storage.BlockManager: BlockManager stopped
2023-05-17 19:20:33,358 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
2023-05-17 19:20:33,360 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2023-05-17 19:20:33,373 INFO spark.SparkContext: Successfully stopped SparkContext
